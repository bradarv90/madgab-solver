{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import cmudict, wordnet\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "import pprint\n",
    "import itertools\n",
    "import copy\n",
    "from types import *\n",
    "import collections\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cmudict to /home/ds/nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ds/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"cmudict\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VOWELS = ['A', 'E', 'I', 'O', 'U']\n",
    "\n",
    "CMUDICT_DICT = collections.defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VOWELS_IN_CMUDICT = set(pro\n",
    "                        for (_, pron) in cmudict.entries()\n",
    "                        for pro in pron\n",
    "                        if pro[0] in VOWELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VOWELS_DICT = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input1 = \"eye mull of mush sheen\"\n",
    "output1 = \"i'm a love machine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_vowel_combinations(middle_letter):\n",
    "    if middle_letter not in VOWELS_DICT.keys():\n",
    "        VOWELS_DICT[middle_letter] = [pro\n",
    "                                      for pro in VOWELS_IN_CMUDICT\n",
    "                                      if pro[1] == middle_letter]\n",
    "    return VOWELS_DICT[middle_letter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_sentence(sentence):\n",
    "    words = [word for word in sentence.split()]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_syllables(w):\n",
    "    if w not in CMUDICT_DICT.keys():\n",
    "        CMUDICT_DICT[w] = \\\n",
    "            [pron for (word, pron) in cmudict.entries() if word == w]\n",
    "    return CMUDICT_DICT[w]\n",
    "\n",
    "\n",
    "def get_syllables_of_sentence(words):\n",
    "    return [get_syllables(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def possible_pronunciations(syllables):\n",
    "    # input: [[[u'AH1', u'V'], [u'AH0', u'V']], [[u'W']]]\n",
    "    # pronunciations: [([u'AH1', u'V'], [u'W']),([u'AH0', u'V'], [u'W'])]\n",
    "    # output: [[u'AH1', u'V', u'W'], [u'AH0', u'V', u'W']]\n",
    "    pronunciations = [t for t in itertools.product(*syllables)]\n",
    "    \n",
    "    collapse_sentence = lambda acc, word: acc.extend(word) or acc\n",
    "\n",
    "    outer = [reduce(collapse_sentence,\n",
    "                    one_pronunciation, [])\n",
    "             for one_pronunciation in pronunciations]\n",
    "    return outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def post_processing(pronunciations):\n",
    "    # turn AH0 -> [AH0, AH1, EH0, EH1, IH0, IH1, OH0, OH1, UH0, UH1] # not exactly though\n",
    "    # two or more of a sound gets knocked off [SH, SH] -> [[SH, ''], [SH]]\n",
    "    #                                           ->[[SH, SH], ['', SH]]\n",
    "    # turn B -> [B]\n",
    "    # then do cartesian product to build all possible strings\n",
    "    copy_of_pronunciations = copy.deepcopy(pronunciations)\n",
    "    for pronunciation in pronunciations:\n",
    "        for sound_loc in range(len(pronunciation)):\n",
    "            sound = pronunciation[sound_loc]\n",
    "            if sound_loc + 1 < len(pronunciation) \\\n",
    "                    and pronunciation[sound_loc + 1] == pronunciation[sound_loc]:\n",
    "                deal_with_duplicates(pronunciation, sound_loc)\n",
    "            if pronunciation[sound_loc][0] in VOWELS:\n",
    "                deal_with_vowels(pronunciation, sound_loc)\n",
    "            if pronunciation[sound_loc] == sound:\n",
    "                pronunciation[sound_loc] = [sound]\n",
    "        copy_of_pronunciations += map(lambda x: list(x),\n",
    "                                      itertools.product(*pronunciation))\n",
    "    return copy_of_pronunciations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deal_with_duplicates(pronunciation, sound_loc):\n",
    "    pronunciation[sound_loc] = [pronunciation[sound_loc], u'']\n",
    "\n",
    "def deal_with_vowels(pronunciation, sound_loc):\n",
    "    middle_letter = pronunciation[sound_loc][1]\n",
    "    pronunciation[sound_loc] = find_vowel_combinations(middle_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_empty_quotes(pronunciations):\n",
    "    # exists to remove empty quotes in pronunciations\n",
    "    # turn [[SH, SH], ['', SH]] -> [[SH, SH], [SH]]\n",
    "    for pronunciation_loc in range(len(pronunciations)):\n",
    "        pronunciation = pronunciations[pronunciation_loc]\n",
    "        pronunciations[pronunciation_loc] = [sound\n",
    "                                             for sound in pronunciation\n",
    "                                             if sound != '']\n",
    "    return pronunciations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_two_strings_match(input_pronunciations, output_pronunciations):\n",
    "    return any(output_pronunciation == list(input_pronunciation)\n",
    "               for input_pronunciation in input_pronunciations\n",
    "               for output_pronunciation in output_pronunciations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_two_sentences(input, output, run_everything=False):\n",
    "    input_syllables = get_syllables_of_sentence(tokenize_sentence(input))\n",
    "    output_syllables = get_syllables_of_sentence(tokenize_sentence(output))\n",
    "    input_pronunciations = remove_empty_quotes(\n",
    "        post_processing(\n",
    "            possible_pronunciations(input_syllables)))\n",
    "    prettied_input_pronunciations = set([tuple(x) for x in input_pronunciations])\n",
    "    output_pronunciations = possible_pronunciations(output_syllables)\n",
    "    print(do_two_strings_match(prettied_input_pronunciations, output_pronunciations))\n",
    "    if (run_everything):\n",
    "        do_everything(prettied_input_pronunciations)\n",
    "\n",
    "def do_everything(pretty_input_pronunciations):\n",
    "    # this part is too slow and/or doesn't work\n",
    "    a = [(word, pron, pronunciation)\n",
    "         for pronunciation in pretty_input_pronunciations\n",
    "         for (word, pron)\n",
    "         in cmudict.entries()\n",
    "         if pronunciation[:len(pron)] == pron]\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "compare_two_sentences(input1, output1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
